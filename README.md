# ğŸ—ï¸ pipeline-databricks-azure

Este repositÃ³rio foi criado como parte de um estudo prÃ¡tico para construir um pipeline de dados utilizando **Azure Data Factory** e **Azure Databricks**, com o objetivo de realizar ingestÃ£o e tratamento de dados de imÃ³veis.

> âš ï¸ **Aviso:** Este pipeline nÃ£o estÃ¡ mais funcional, pois os recursos da Azure foram removidos. O projeto permanece como **portfÃ³lio**.

---

## ğŸ’¡ Objetivo

Construir um pipeline moderno e escalÃ¡vel para:

1. **IngestÃ£o de dados brutos** de imÃ³veis.
2. **Processamento inicial (camada Bronze)** usando Databricks.
3. **TransformaÃ§Ãµes e limpeza (camada Silver)** tambÃ©m via Databricks.
4. OrganizaÃ§Ã£o dos dados para futuras anÃ¡lises ou camadas superiores (como Gold ou BI).

---

## ğŸ› ï¸ Tecnologias e ServiÃ§os Utilizados

- **Azure Data Factory**: OrquestraÃ§Ã£o das atividades de ingestÃ£o e transformaÃ§Ã£o.
- **Azure Databricks**: Processamento dos dados usando notebooks em PySpark.
- **Azure Data Lake Storage**: Armazenamento das camadas Bronze e Silver.
- **ARM Templates**: Para provisionamento de recursos via cÃ³digo.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ databricks-curso-alura/      # Templates e parÃ¢metros de implantaÃ§Ã£o
â”œâ”€â”€ factory/                     # DefiniÃ§Ã£o do Data Factory
â”œâ”€â”€ linkedService/              # ConexÃµes com serviÃ§os externos (ex: Databricks)
â”œâ”€â”€ notebooks/                  # Notebooks usados no Databricks (Scala + Python)
â”œâ”€â”€ pipeline/                   # Pipelines definidos no ADF
â”œâ”€â”€ trigger/                    # Gatilhos de execuÃ§Ã£o
â”œâ”€â”€ publish_config.json         # ConfiguraÃ§Ã£o de publicaÃ§Ã£o
â”œâ”€â”€ README.md                   # Este arquivo
â””â”€â”€ .gitignore
```

---

## ğŸ”„ Fluxo do Pipeline

1. **Trigger do ADF** inicia a execuÃ§Ã£o com base em agendamento ou manual.
2. Pipeline realiza a **ingestÃ£o dos dados brutos** e os armazena na camada Bronze.
3. Um notebook no Databricks Ã© executado para **tratar e transformar os dados**.
4. Os dados tratados sÃ£o salvos na **camada Silver**.

---

## ğŸ“Œ ObservaÃ§Ãµes

- Os notebooks foram desenvolvidos em **SCALA** principalmente, com foco em tratamento de dados estruturados.
- O projeto Ã© fruto do curso da Alura sobre Azure Databricks e Data Factory.
- Alguns nomes e configuraÃ§Ãµes seguem a estrutura proposta durante o curso.

---

## ğŸ‘¤ Autor

- [queirozene](https://github.com/queirozene)
